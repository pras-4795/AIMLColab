{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pras-4795/AIMLColab/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmogvI1locX",
        "colab_type": "code",
        "outputId": "bd064447-810f-480e-9b68-283336bf110d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "5858 from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwgPE_Zkl3Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Dataset/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye6YMZbMrfHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def process_text(text):\n",
        "    # Make all the strings lowercase and remove non alphabetic characters\n",
        "    text = re.sub('[^A-Za-z]', ' ', text.lower())\n",
        "\n",
        "    # Tokenize the text; this is, separate every sentence into a list of words\n",
        "    # Since the text is already split into sentences you don't have to call sent_tokenize\n",
        "    tokenized_text = word_tokenize(text)\n",
        "\n",
        "    # Remove the stopwords and stem each word to its root\n",
        "    clean_text = [\n",
        "        stemmer.stem(word) for word in tokenized_text\n",
        "        if word not in stopwords.words('english')\n",
        "    ]\n",
        "\n",
        "    # Remember, this final output is a list of words\n",
        "    return clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-kxIAyzNJZX",
        "colab_type": "code",
        "outputId": "1c85d3e4-1ca3-4d54-de6d-fd622eae089f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoNkds021W1U",
        "colab_type": "code",
        "outputId": "3ad4d8d5-8a16-49b2-e281-76950fb73bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.topic.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohs5Ei8Gs7m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the first row, since it only has the labels\n",
        "reviews =df.copy()\n",
        "\n",
        "texts = [row[1][0] for row in reviews.iterrows()]\n",
        "topics = [row[1][2] for row in reviews.iterrows()]\n",
        "\n",
        "# Process the texts to so they are ready for training\n",
        "# But transform the list of words back to string format to feed it to sklearn\n",
        "texts = [\" \".join(process_text(text)) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgetvev2Rpe",
        "colab_type": "code",
        "outputId": "8614e8f1-d2f7-45a0-83bf-1b3887f5a905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "texts[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['noth help lost even work eat healthi curb appetit anyth',\n",
              " 'noth help lost even work eat healthi curb appetit anyth',\n",
              " 'bought bag immedi open one put trash bag split side open anoth bag cover split bag also split side x buy end throw box away',\n",
              " 'gave allerg reaction face',\n",
              " 'compar name brand wipe famili littl kid use lot wipe cut sticki mess small thin might ok wipe less often use place good tackl actual mess also care lemon scent felt strong']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gWNUCV7vNqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "matrix = TfidfVectorizer(max_features=750)\n",
        "vectors = matrix.fit_transform(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13FIjGBCun4",
        "colab_type": "code",
        "outputId": "ecc551d6-fd61-4a6e-ae03-553d90f92080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_train_res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZLoBgYfvRcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "vectors_train, vectors_test, topics_train, topics_test = train_test_split(vectors, topics, random_state = 5)\n",
        "\n",
        "sm = SMOTE(random_state=2, k_neighbors=1)\n",
        "#smote_enn = SMOTEENN(random_state=0, smote=sm)\n",
        "smote_tomek = SMOTETomek(random_state=0, smote=sm)\n",
        "\n",
        "X_train_res, y_train_res = smote_tomek.fit_resample(vectors_train, topics_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtIzL1xvy-",
        "colab_type": "code",
        "outputId": "4489ee7c-09cd-4a7d-824f-9cf043ec587c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5959, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzZdZbBHvUpF",
        "colab_type": "code",
        "outputId": "6b1722cc-b9f3-428f-fc3e-d18fa3264761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier(silent=0)\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict with the testing set\n",
        "topics_pred = classifier.predict(vectors_test)\n",
        "\n",
        "# ...and measure the accuracy of the results\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(topics_test, topics_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "               Allergic       0.61      0.42      0.50       149\n",
            "       Bad Taste/Flavor       0.60      0.44      0.51       273\n",
            "      Color and texture       0.40      0.53      0.46        59\n",
            "        Customer Issues       0.33      0.33      0.33         3\n",
            "       Customer Service       0.21      0.25      0.23        57\n",
            "            Didn't Like       0.07      0.12      0.09         8\n",
            "                 Expiry       0.71      0.69      0.70        36\n",
            "    False Advertisement       0.56      0.56      0.56         9\n",
            "           Hard to Chew       0.00      0.00      0.00         1\n",
            "Inferior to competitors       0.64      0.41      0.50        17\n",
            "            Ingredients       0.32      0.37      0.34        51\n",
            "          Not Effective       0.60      0.66      0.63       158\n",
            "              Packaging       0.65      0.65      0.65       126\n",
            "                Pricing       0.57      0.48      0.52        33\n",
            "   Quality/Contaminated       0.47      0.42      0.44       191\n",
            "  Shipment and delivery       0.70      0.73      0.71       100\n",
            "             Smells Bad       0.33      0.33      0.33        36\n",
            "                Texture       0.42      0.63      0.50        83\n",
            "              Too Sweet       0.33      0.62      0.43        24\n",
            "     Too big to swallow       0.57      0.61      0.59        57\n",
            " Wrong Product received       0.33      0.74      0.46        19\n",
            "\n",
            "               accuracy                           0.52      1490\n",
            "              macro avg       0.45      0.48      0.45      1490\n",
            "           weighted avg       0.54      0.52      0.52      1490\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fpbVqI6wZJY",
        "colab_type": "code",
        "outputId": "05683769-6cdf-4e1a-ef31-6ac295312eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from xgboost import XGBClassifier\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict with the testing set\n",
        "topics_pred = classifier.predict(vectors_test)\n",
        "\n",
        "# ...and measure the accuracy of the results\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(topics_test, topics_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "               Allergic       0.35      0.29      0.32       149\n",
            "       Bad Taste/Flavor       0.35      0.41      0.38       273\n",
            "      Color and texture       0.17      0.15      0.16        59\n",
            "        Customer Issues       0.25      0.33      0.29         3\n",
            "       Customer Service       0.16      0.18      0.17        57\n",
            "            Didn't Like       0.00      0.00      0.00         8\n",
            "                 Expiry       0.63      0.53      0.58        36\n",
            "    False Advertisement       0.38      0.33      0.35         9\n",
            "           Hard to Chew       0.00      0.00      0.00         1\n",
            "Inferior to competitors       0.60      0.18      0.27        17\n",
            "            Ingredients       0.20      0.22      0.21        51\n",
            "          Not Effective       0.46      0.51      0.48       158\n",
            "              Packaging       0.51      0.55      0.53       126\n",
            "                Pricing       0.55      0.33      0.42        33\n",
            "   Quality/Contaminated       0.28      0.24      0.25       191\n",
            "  Shipment and delivery       0.57      0.59      0.58       100\n",
            "             Smells Bad       0.23      0.17      0.19        36\n",
            "                Texture       0.18      0.20      0.19        83\n",
            "              Too Sweet       0.24      0.33      0.28        24\n",
            "     Too big to swallow       0.54      0.49      0.51        57\n",
            " Wrong Product received       0.29      0.37      0.33        19\n",
            "\n",
            "               accuracy                           0.36      1490\n",
            "              macro avg       0.33      0.30      0.31      1490\n",
            "           weighted avg       0.37      0.36      0.36      1490\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}